Step-by-step plan
1. Figure out how to extract and manipulate data from the MNIST 
2. Implement gradient descent (import from already completed python files)
3. Plan out general architecture for neural network
    a. Number of input units: dimensions of x(i)
    b. Number of output units: number of classes y(i)
    c. Number of hidden units per layer
    d. Default: 1 hidden layer, randomize initial parameters Theta
4. Implement forward propagation
5. Implement cost function
6. Implement back prop to compute partial derivatives
7. Gradient checking to check implementation of back prop
8. Gradient descent for optimizing the cost function

Reminder to split the test dataset into 50/50 CV/Test.

F-score history (F-score = 2PR/(P+R))

